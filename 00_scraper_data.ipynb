{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344f69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ff7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = requests.Session()\n",
    "# headers = {\n",
    "#     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "#     'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "#     'Accept-Language': 'vi,en-US;q=0.9,en;q=0.8',\n",
    "#     'Connection': 'keep-alive',\n",
    "#     'Referer': 'https://www.nhatot.com/',\n",
    "#     'Sec-Fetch-Dest': 'document',\n",
    "#     'Sec-Fetch-Mode': 'navigate',\n",
    "#     'Sec-Fetch-Site': 'same-origin',\n",
    "#     'Sec-Fetch-User': '?1',\n",
    "#     'Upgrade-Insecure-Requests': '1',\n",
    "#     'Cache-Control': 'max-age=0',\n",
    "# }\n",
    "# url = \"https://alonhadat.com.vn/-nha-pho-shophouse-bds-trung-nguyen-gia-7-9-ty-chi-01-can-duy-nhat-16379341.html\"\n",
    "# response = session.get(url, headers=headers, timeout=15)\n",
    "# soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "# test = soup.select('#ctl00_content_pc_content > main > article > section.moreinfor1 > table')\n",
    "# print(test)\n",
    "# if test:\n",
    "#     t = test[0].get_text().split('\\n')\n",
    "#     print(t)\n",
    "# else:\n",
    "#     print(\"Không tìm thấy phần tử cần thiết.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9396456b",
   "metadata": {},
   "source": [
    "# HDSD\n",
    "\n",
    "- Đầu vào:\n",
    "    - `scraper_links=True/False`: Quyết định có cào link hay không, chỉ không nếu đã có sẵn link và `have_link=True`\n",
    "    - `have_link=True/False` : Sẽ lấy link từ file csv lưu link nếu đã có, nếu lấy file thì sẽ không bật `scraper_links`\n",
    "        - **2 giá trị `scraper_links` và `have_link` sẽ đối ngược nhau**\n",
    "    - `scraper_data=True/False`: lấy link cào data, hoặc `False` để chỉ cào link và lưu trữ, phục vụ cho debug\n",
    "    - `start_from_links` = int: Bắt đầu cào từ chỉ số link cụ thể (nếu có danh sách link có sẵn)\n",
    "    - `start_from_page` = int: Bắt đầu thu nhập link từ page (vì trogn quá tình thu nhập link có thể lỗi hoặc thu nhập quá ít muốn thi nhập thêm, mà không muốn bị lặp dẫn đến tốn thời gian)\n",
    "    - `end_to_page` = int: Thu nhập link đến trang thứ page\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- Hàm trước tiên sẽ thu nhập các đường link từ trang chủ, kéo qua đến trang `page_per_source`, sau đó sẽ truy cập từng trang và bắt đầu thu nhập dữ liệu trong link cụ thể bao gồm:\n",
    "    -   Tiêu đề\n",
    "    -   Giá tổng thể\n",
    "    -   Diện tích đất\n",
    "    -   Đơn vị\n",
    "    -   Địa chỉ phố\n",
    "    -   Địa chỉ phường\n",
    "    -   Thành phố\n",
    "    -   Thời gian update giá\n",
    "    -   Tìm bảng\n",
    "    -   Mã tin\n",
    "    -   Hướng\n",
    "    -   Loại tin\n",
    "    -   Đường trước nhà\n",
    "    -   Loại BDS\n",
    "    -   Pháp lý\n",
    "    -   Chiều ngang\n",
    "    -   Chiều dài \n",
    "    -   Số lầu \n",
    "    -   Số phòng ngủ \n",
    "    -   Phòng ăn (có/không)\n",
    "    -   Nhà bếp (có/không)\n",
    "    -   Sân thượng (có/không)\n",
    "    -   Chỗ để xe hơi (có/không)\n",
    "    -   Chính chủ hay không (có/khôngkhông)\n",
    "\n",
    "- Hàm sẽ xoay tua các agent để tránh bị block, cào hiện tại trong khoảng thời gian random 3-6s cho mỗi đường link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185073f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thiet lap logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "class cho_van_tot:\n",
    "    def __init__(self, output_dir='./data_output'):  # Đặt đường dẫn mặc định là tương đối\n",
    "        self.output_dir = output_dir\n",
    "        self.request_count = 0\n",
    "        self.max_requests_per_minute = 10\n",
    "        self.batch_size = 10\n",
    "        self.use_proxy=None\n",
    "        self.PROXY_LIST = None\n",
    "        self.user_agents = [\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/122.0',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/122.0'\n",
    "        ]\n",
    "        self.headers = {\n",
    "            'User-Agent': self.user_agents[0], # Đặt User-Agent mặc định lúc khởi tạo\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "            'Accept-Language': 'vi,en-US;q=0.9,en;q=0.8',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Referer': 'https://alonhadat.com.vn/',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'same-origin',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "        }\n",
    "\n",
    "        self.data = []\n",
    "        self.session = requests.Session()\n",
    "\n",
    "        \n",
    "        # Tạo thư mục output_dir nếu chưa có\n",
    "        try:\n",
    "            os.makedirs(self.output_dir, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"1.error :{str(e)}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    \n",
    "    def scraper_link_totot(self, use_proxy=False, PROXY_LIST, scraper_links=True, have_link=False, scraper_data=True, start_from_links=0, start_from_page=1 , end_to_page=100):\n",
    "    \n",
    "        if have_link == False and scraper_links == True:\n",
    "            article_links = []\n",
    "\n",
    "            categories = ['can-ban-nha-dat']\n",
    "\n",
    "            for category in categories:\n",
    "                for page in range(start_from_page, end_to_page + 1):\n",
    "                    try:\n",
    "                        urls = [f\"https://alonhadat.com.vn/{category}/trang-{page}\"]\n",
    "                        for url in urls:\n",
    "                            time.sleep(random.uniform(3, 6))  # Tăng thời gian chờ\n",
    "                            self.headers['User-Agent'] = random.choice(self.user_agents) # Xoay vòng User-Agent\n",
    "                            if self.use_proxy:\n",
    "                                # Xoay vòng proxy\n",
    "                                current_proxies = random.choice(self.PROXY_LIST)\n",
    "                                response = self.session.get(\n",
    "                                    url, \n",
    "                                    headers=self.headers,\n",
    "                                    proxies=current_proxies, \n",
    "                                    timeout=15\n",
    "                                )\n",
    "                            else:\n",
    "                                response = self.session.get(\n",
    "                                    url, \n",
    "                                    headers=self.headers,\n",
    "                                    timeout=15\n",
    "                                )\n",
    "                            if response.status_code == 200:\n",
    "                                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                                articles = []\n",
    "                                articles.extend(soup.select(\"article > a\"))\n",
    "                                for a in articles:\n",
    "                                    href = a.get('href')\n",
    "                                    if href and not href.startswith(\"http\"):\n",
    "                                        href = f\"https://alonhadat.com.vn/{href}\"\n",
    "                                        article_links.append({\n",
    "                                                \"url\": href,\n",
    "                                        })\n",
    "                                logging.info(f\"da thu thap {len(article_links)} lien ket tu alo nha dat - chuyen muc {category} - trang {page}\")\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "            \n",
    "            unique_links = []\n",
    "            unique_urls = set()\n",
    "            for link in article_links:\n",
    "                if link[\"url\"] not in unique_urls:\n",
    "                    unique_urls.add(link[\"url\"])\n",
    "                    unique_links.append(link)\n",
    "            logging.info(f\"tong so lien ket duy nhat: {len(unique_links)}\")\n",
    "\n",
    "            pd.DataFrame(unique_links).to_csv(os.path.join(self.output_dir, \"article_links.csv\"), index=False, encoding='utf-8') \n",
    "            \n",
    "        elif have_link == True and scraper_links == False:\n",
    "            read_unique_links = pd.read_csv(os.path.join(self.output_dir, \"article_links.csv\"))  \n",
    "            unique_links = read_unique_links.to_dict('records')\n",
    "        \n",
    "        \n",
    "        # Nếu scraper_data = False, sẽ chỉ cào link\n",
    "        if scraper_data == True:\n",
    "            links_to_process = unique_links[start_from_links:]\n",
    "            logging.info(f\"se xu ly {len(links_to_process)} link (bo qua {start_from_links} link dau)\")\n",
    "\n",
    "            csv_path = os.path.join(self.output_dir, \"all_articles.csv\")  \n",
    "            total_saved = 0  # Thêm biến đếm tổng số bài đã lưu\n",
    "\n",
    "            for num, article_info in tqdm(enumerate(links_to_process), total=len(links_to_process), desc=\"thu nhap du lieu nha van dat\"):\n",
    "                try:\n",
    "                    actual_index = start_from_links + num\n",
    "\n",
    "                    article_data = self.scraper_data_cho_van_tot(article_info['url'])\n",
    "                    if article_data:\n",
    "                        self.data.append(article_data)\n",
    "                        \n",
    "                        # Kiểm tra batch_count ---SAU KHI--- thêm vào data\n",
    "                        if len(self.data) >= self.batch_size:\n",
    "                            df = pd.DataFrame(self.data)\n",
    "                            header = not os.path.exists(csv_path)\n",
    "                            df.to_csv(csv_path, mode='a', header=header, index=False, encoding='utf-8')\n",
    "\n",
    "                            total_saved += len(self.data)  # Cộng dồn số bài đã lưu\n",
    "                            logging.info(f\"da luu batch: {len(self.data)} bai viet (tong: {total_saved}) (link {actual_index + 1}/{len(unique_links)})\")\n",
    "\n",
    "                            self.data = []  # Reset sau khi lưu\n",
    "\n",
    "                        time.sleep(random.uniform(3, 6))  \n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"6.Loi khi thu thap data tu link {actual_index + 1} - {article_info['url']}: {str(e)}\")\n",
    "\n",
    "            # Lưu batch còn lại\n",
    "            if self.data:\n",
    "                df = pd.DataFrame(self.data)\n",
    "                header = not os.path.exists(csv_path)\n",
    "                df.to_csv(csv_path, mode='a', header=header, index=False, encoding='utf-8')\n",
    "                total_saved += len(self.data)\n",
    "                logging.info(f\"da luu batch cuoi: {len(self.data)} bai viet\")\n",
    "\n",
    "            logging.info(f\"da hoan thanh thu nhap data cho van tot: TONG CONG {total_saved} bai viet\")\n",
    "\n",
    "    def scraper_data_cho_van_tot(self, url):\n",
    "        max_retries = 3\n",
    "        retry_count = 0\n",
    "\n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                self.headers['User-Agent'] = random.choice(self.user_agents) # Xoay vòng User-Agent\n",
    "                if self.use_proxy:\n",
    "                    # Xoay vòng proxy\n",
    "                    current_proxies = random.choice(self.PROXY_LIST)\n",
    "                    response = self.session.get(\n",
    "                        url, \n",
    "                        headers=self.headers,\n",
    "                        proxies=current_proxies, \n",
    "                        timeout=15\n",
    "                    )\n",
    "                else:\n",
    "                    response = self.session.get(\n",
    "                        url, \n",
    "                        headers=self.headers,\n",
    "                        timeout=15\n",
    "                    )\n",
    "                \n",
    "                if response.status_code == 429:\n",
    "                    retry_after = 60  # Mặc định 60s\n",
    "                    logging.warning(f\"Lỗi 429 - chờ {retry_after} giây trước khi thử lại...\")\n",
    "                    time.sleep(retry_after)\n",
    "                    retry_count += 1\n",
    "                    continue\n",
    "                if response.status_code != 200:\n",
    "                    logging.warning(f\"7.khong the truy cap {url}, ma trang thai:{response.status_code}\")\n",
    "                    retry_count += 1\n",
    "                    time.sleep(random.uniform(3, 6))  \n",
    "                    continue\n",
    "                    \n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                def safe_scraper(selector, default=None):\n",
    "                    try:\n",
    "                        element = soup.select_one(selector)\n",
    "                        return element.text.strip() if element else default\n",
    "                    except:\n",
    "                        return default\n",
    "                    \n",
    "                # Tiêu đề\n",
    "                title = safe_scraper('#ctl00_content_pc_content > main > article > header > h1')\n",
    "                # Giá tổng thể\n",
    "                price = safe_scraper('#ctl00_content_pc_content > main > article > section.more-info > span.price > data')\n",
    "\n",
    "                # Diện tích đất + đơn vị, vì ở đây thiết kế bị lồng và chứa các chuỗi rỗng khi tách nên cần lấy thông tin không phải rỗng\n",
    "                size_unit = safe_scraper('#ctl00_content_pc_content > main > article > section.more-info > span.area > span').split('\\n')\n",
    "                size_unit_notnull = [item.strip() for item in size_unit if item.strip()]\n",
    "\n",
    "                # Diện tích đất\n",
    "                size = size_unit_notnull[0]\n",
    "                # Đơn vị\n",
    "                unit = size_unit_notnull[1]\n",
    "                # Địa chỉ phố\n",
    "                streetAddress = safe_scraper('#ctl00_content_pc_content > main > article > address > span:nth-child(1)')\n",
    "                # Địa chỉ phường\n",
    "                addressLocality = safe_scraper('#ctl00_content_pc_content > main > article > address > span:nth-child(2)')\n",
    "                # Thành phố\n",
    "                addressRegion = safe_scraper('#ctl00_content_pc_content > main > article > address > span:nth-child(3)')\n",
    "                # Thời gian update giá\n",
    "                time_update = soup.select('#ctl00_content_pc_content > main > article > header > time')[0].get('datetime')\n",
    "\n",
    "                # Tìm bảng\n",
    "                table = soup.select_one('#ctl00_content_pc_content > main > article > section.moreinfor1 > table')\n",
    "\n",
    "                def find_element_custom(a, b):\n",
    "                    tag = table.find_all('tr')[a].find_all('td')[b]\n",
    "                    text = 'yes' if tag.find('img') else tag.text.strip()\n",
    "                    if text == '---' or text == '_':\n",
    "                        text = None\n",
    "                    return text\n",
    "\n",
    "                # Mã tin\n",
    "                post_id = find_element_custom(0, 1)\n",
    "                # Hướng\n",
    "                direction = find_element_custom(0, 3)\n",
    "                # Loại tin\n",
    "                listing_type = find_element_custom(1, 1)\n",
    "                # Đường trước nhà\n",
    "                road_width = find_element_custom(1, 3)\n",
    "                # Loại BDS\n",
    "                property_type = find_element_custom(2, 1)\n",
    "                # Pháp lý\n",
    "                legal_documents = find_element_custom(2, 3)\n",
    "                # Chiều ngang\n",
    "                width = find_element_custom(3, 1)\n",
    "                # Chiều dài\n",
    "                length = find_element_custom(4, 1)\n",
    "                # Số lầu\n",
    "                num_floors = find_element_custom(3, 3)\n",
    "                # Số phòng ngủ\n",
    "                num_bedrooms = find_element_custom(4, 3)\n",
    "                # Phòng ăn\n",
    "                has_dining_room = find_element_custom(0, 5)\n",
    "                # Nhà bếp\n",
    "                has_kitchen = find_element_custom(1, 5)\n",
    "                # Sân thượng\n",
    "                has_rooftop = find_element_custom(2, 5)\n",
    "                # Chỗ để xe hơi\n",
    "                has_parking = find_element_custom(3, 5)\n",
    "                # Chính chủ\n",
    "                is_owner = find_element_custom(4, 5)\n",
    "                    \n",
    "                return {\n",
    "                    \"title\": title,\n",
    "                    \"price\": price,\n",
    "                    \"size\": size,\n",
    "                    \"unit\": unit,\n",
    "                    \"streetAddress\": streetAddress,\n",
    "                    \"addressLocality\": addressLocality,\n",
    "                    \"addressRegion\": addressRegion,\n",
    "                    \"time_update\": time_update,\n",
    "                    \"post_id\": post_id,\n",
    "                    \"direction\": direction,\n",
    "                    \"listing_type\": listing_type,\n",
    "                    \"road_width\": road_width,\n",
    "                    \"property_type\": property_type,\n",
    "                    \"legal_documents\": legal_documents,\n",
    "                    \"width\": width,\n",
    "                    \"length\": length,\n",
    "                    \"num_floors\": num_floors,\n",
    "                    \"num_bedrooms\": num_bedrooms,\n",
    "                    \"has_dining_room\": has_dining_room,\n",
    "                    \"has_kitchen\": has_kitchen,\n",
    "                    \"has_rooftop\": has_rooftop,\n",
    "                    \"has_parking\": has_parking,\n",
    "                    \"is_owner\": is_owner\n",
    "                }\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                retry_count += 1\n",
    "                logging.warning(f\"loi khi thu thap bai viet (lan {retry_count}/{max_retries}): {url}\")\n",
    "                if retry_count == max_retries:\n",
    "                    logging.error(f\"loi khi thu thap bai viet sau {max_retries} lan thu: {url}\")\n",
    "                    return None\n",
    "                time.sleep(random.uniform(3, 6))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"loi khong xac dinh khi xu ly bai viet {url}: {str(e)}\")\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "        \n",
    "    def run(self, PROXY_LIST, use_proxy=False, scraper_links=True, have_link=False, scraper_data=True, start_from_links=0, start_from_page=1, end_to_page=1):\n",
    "        logging.info(f\"bat dau qua trinh thu nhap du lieu\")\n",
    "        self.scraper_link_totot(scraper_links = scraper_links, \n",
    "                                have_link=have_link, \n",
    "                                scraper_data=scraper_data, \n",
    "                                start_from_links=start_from_links, \n",
    "                                start_from_page=start_from_page, \n",
    "                                end_to_page=end_to_page\n",
    "                                )\n",
    "\n",
    "        logging.info(f\"da hoan thanh qua trinh thu nhap du lieu\")\n",
    "        logging.info(f\"tong so bai viet da thu thap: {len(self.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = cho_van_tot(PROXY_LIST=PROXY_LIST)\n",
    "scraper.run(scraper_links=False,\n",
    "            use_proxy=True,\n",
    "            PROXY_LIST=PROXY_LIST,\n",
    "            have_link=True,\n",
    "            scraper_data=True, \n",
    "            start_from_links=404, \n",
    "            start_from_page=0, \n",
    "            end_to_page=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71a1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354fd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thiet lap logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "class cho_van_tot:\n",
    "    def __init__(self, PROXY_LIST, output_dir='./data_output'):  # Đặt đường dẫn mặc định là tương đối\n",
    "        self.output_dir = output_dir\n",
    "        self.request_count = 0\n",
    "        self.max_requests_per_minute = 10\n",
    "        self.batch_size = 10\n",
    "        self.PROXY_LIST = PROXY_LIST\n",
    "        self.user_agents = [\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/122.0',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/122.0'\n",
    "        ]\n",
    "        self.headers = {\n",
    "            'User-Agent': self.user_agents[0], # Đặt User-Agent mặc định lúc khởi tạo\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "            'Accept-Language': 'vi,en-US;q=0.9,en;q=0.8',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Referer': 'https://alonhadat.com.vn/',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'same-origin',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "        }\n",
    "\n",
    "        self.data = []\n",
    "        self.session = requests.Session()\n",
    "\n",
    "        \n",
    "        # Tạo thư mục output_dir nếu chưa có\n",
    "        try:\n",
    "            os.makedirs(self.output_dir, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"1.error :{str(e)}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    \n",
    "    def scraper_link_totot(self, scraper_links=True, have_link=False, scraper_data=True, start_from_links=0, start_from_page=1 , end_to_page=100):\n",
    "    \n",
    "        if have_link == False and scraper_links == True:\n",
    "            article_links = []\n",
    "\n",
    "            categories = ['can-ban-nha-dat']\n",
    "\n",
    "            for category in categories:\n",
    "                for page in range(start_from_page, end_to_page + 1):\n",
    "                    try:\n",
    "                        urls = [f\"https://alonhadat.com.vn/{category}/trang-{page}\"]\n",
    "                        for url in urls:\n",
    "                            time.sleep(random.uniform(3, 6))  # Tăng thời gian chờ\n",
    "                            self.headers['User-Agent'] = random.choice(self.user_agents) # Xoay vòng User-Agent\n",
    "                            # Xoay vòng proxy\n",
    "                            current_proxies = random.choice(self.PROXY_LIST)\n",
    "                            response = self.session.get(\n",
    "                                url, \n",
    "                                headers=self.headers,\n",
    "                                proxies=current_proxies, \n",
    "                                timeout=15\n",
    "                            )\n",
    "                            if response.status_code == 200:\n",
    "                                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                                articles = []\n",
    "                                articles.extend(soup.select(\"article > a\"))\n",
    "                                for a in articles:\n",
    "                                    href = a.get('href')\n",
    "                                    if href and not href.startswith(\"http\"):\n",
    "                                        href = f\"https://alonhadat.com.vn/{href}\"\n",
    "                                        article_links.append({\n",
    "                                                \"url\": href,\n",
    "                                        })\n",
    "                                logging.info(f\"da thu thap {len(article_links)} lien ket tu alo nha dat - chuyen muc {category} - trang {page}\")\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "            \n",
    "            unique_links = []\n",
    "            unique_urls = set()\n",
    "            for link in article_links:\n",
    "                if link[\"url\"] not in unique_urls:\n",
    "                    unique_urls.add(link[\"url\"])\n",
    "                    unique_links.append(link)\n",
    "            logging.info(f\"tong so lien ket duy nhat: {len(unique_links)}\")\n",
    "\n",
    "            pd.DataFrame(unique_links).to_csv(os.path.join(self.output_dir, \"article_links.csv\"), index=False, encoding='utf-8') \n",
    "            \n",
    "        elif have_link == True and scraper_links == False:\n",
    "            read_unique_links = pd.read_csv(os.path.join(self.output_dir, \"article_links.csv\"))  \n",
    "            unique_links = read_unique_links.to_dict('records')\n",
    "        \n",
    "        \n",
    "        # Nếu scraper_data = False, sẽ chỉ cào linklink\n",
    "        if scraper_data == True:\n",
    "            links_to_process = unique_links[start_from_links:]\n",
    "            logging.info(f\"se xu ly {len(links_to_process)} link (bo qua {start_from_links} link dau)\")\n",
    "\n",
    "            csv_path = os.path.join(self.output_dir, \"all_articles.csv\")  \n",
    "            total_saved = 0  # Thêm biến đếm tổng số bài đã lưu\n",
    "\n",
    "            for num, article_info in tqdm(enumerate(links_to_process), total=len(links_to_process), desc=\"thu nhap du lieu nha van dat\"):\n",
    "                try:\n",
    "                    actual_index = start_from_links + num\n",
    "\n",
    "                    article_data = self.scraper_data_cho_van_tot(article_info['url'])\n",
    "                    if article_data:\n",
    "                        self.data.append(article_data)\n",
    "                        \n",
    "                        # Kiểm tra batch_count ---SAU KHI--- thêm vào data\n",
    "                        if len(self.data) >= self.batch_size:\n",
    "                            df = pd.DataFrame(self.data)\n",
    "                            header = not os.path.exists(csv_path)\n",
    "                            df.to_csv(csv_path, mode='a', header=header, index=False, encoding='utf-8')\n",
    "\n",
    "                            total_saved += len(self.data)  # Cộng dồn số bài đã lưu\n",
    "                            logging.info(f\"da luu batch: {len(self.data)} bai viet (tong: {total_saved}) (link {actual_index + 1}/{len(unique_links)})\")\n",
    "\n",
    "                            self.data = []  # Reset sau khi lưu\n",
    "\n",
    "                        time.sleep(random.uniform(3, 6))  \n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"6.Loi khi thu thap data tu link {actual_index + 1} - {article_info['url']}: {str(e)}\")\n",
    "\n",
    "            # Lưu batch còn lại\n",
    "            if self.data:\n",
    "                df = pd.DataFrame(self.data)\n",
    "                header = not os.path.exists(csv_path)\n",
    "                df.to_csv(csv_path, mode='a', header=header, index=False, encoding='utf-8')\n",
    "                total_saved += len(self.data)\n",
    "                logging.info(f\"da luu batch cuoi: {len(self.data)} bai viet\")\n",
    "\n",
    "            logging.info(f\"da hoan thanh thu nhap data cho van tot: TONG CONG {total_saved} bai viet\")\n",
    "\n",
    "    def scraper_data_cho_van_tot(self, url):\n",
    "        max_retries = 3\n",
    "        retry_count = 0\n",
    "\n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                self.headers['User-Agent'] = random.choice(self.user_agents) # Xoay vòng User-Agent\n",
    "                # Xoay vòng proxy\n",
    "                current_proxies = random.choice(self.PROXY_LIST)\n",
    "                response = self.session.get(\n",
    "                    url, \n",
    "                    headers=self.headers,\n",
    "                    proxies=current_proxies, \n",
    "                    timeout=15\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 429:\n",
    "                    retry_after = 60  # Mặc định 60s\n",
    "                    logging.warning(f\"Lỗi 429 - chờ {retry_after} giây trước khi thử lại...\")\n",
    "                    time.sleep(retry_after)\n",
    "                    retry_count += 1\n",
    "                    continue\n",
    "                if response.status_code != 200:\n",
    "                    logging.warning(f\"7.khong the truy cap {url}, ma trang thai:{response.status_code}\")\n",
    "                    retry_count += 1\n",
    "                    time.sleep(random.uniform(3, 6))  \n",
    "                    continue\n",
    "                    \n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                def safe_scraper(selector, default=None):\n",
    "                    try:\n",
    "                        element = soup.select_one(selector)\n",
    "                        return element.text.strip() if element else default\n",
    "                    except:\n",
    "                        return default\n",
    "                    \n",
    "                # Tiêu đề\n",
    "                title = safe_scraper('#ctl00_content_pc_content > main > article > header > h1')\n",
    "                # Giá tổng thể\n",
    "                price = safe_scraper('#ctl00_content_pc_content > main > article > section.more-info > span.price > data')\n",
    "\n",
    "                # Diện tích đất + đơn vị, vì ở đây thiết kế bị lồng và chứa các chuỗi rỗng khi tách nên cần lấy thông tin không phải rỗng\n",
    "                size_unit = safe_scraper('#ctl00_content_pc_content > main > article > section.more-info > span.area > span').split('\\n')\n",
    "                size_unit_notnull = [item.strip() for item in size_unit if item.strip()]\n",
    "\n",
    "                # Diện tích đất\n",
    "                size = size_unit_notnull[0]\n",
    "                # Đơn vị\n",
    "                unit = size_unit_notnull[1]\n",
    "                # Địa chỉ phố\n",
    "                streetAddress = safe_scraper('#ctl00_content_pc_content > main > article > address > span:nth-child(1)')\n",
    "                # Địa chỉ phường\n",
    "                addressLocality = safe_scraper('#ctl00_content_pc_content > main > article > address > span:nth-child(2)')\n",
    "                # Thành phố\n",
    "                addressRegion = safe_scraper('#ctl00_content_pc_content > main > article > address > span:nth-child(3)')\n",
    "                # Thời gian update giá\n",
    "                time_update = soup.select('#ctl00_content_pc_content > main > article > header > time')[0].get('datetime')\n",
    "\n",
    "                # Tìm bảng\n",
    "                table = soup.select_one('#ctl00_content_pc_content > main > article > section.moreinfor1 > table')\n",
    "\n",
    "                def find_element_custom(a, b):\n",
    "                    tag = table.find_all('tr')[a].find_all('td')[b]\n",
    "                    text = 'yes' if tag.find('img') else tag.text.strip()\n",
    "                    if text == '---' or text == '_':\n",
    "                        text = None\n",
    "                    return text\n",
    "\n",
    "                # Mã tin\n",
    "                post_id = find_element_custom(0, 1)\n",
    "                # Hướng\n",
    "                direction = find_element_custom(0, 3)\n",
    "                # Loại tin\n",
    "                listing_type = find_element_custom(1, 1)\n",
    "                # Đường trước nhà\n",
    "                road_width = find_element_custom(1, 3)\n",
    "                # Loại BDS\n",
    "                property_type = find_element_custom(2, 1)\n",
    "                # Pháp lý\n",
    "                legal_documents = find_element_custom(2, 3)\n",
    "                # Chiều ngang\n",
    "                width = find_element_custom(3, 1)\n",
    "                # Chiều dài\n",
    "                length = find_element_custom(4, 1)\n",
    "                # Số lầu\n",
    "                num_floors = find_element_custom(3, 3)\n",
    "                # Số phòng ngủ\n",
    "                num_bedrooms = find_element_custom(4, 3)\n",
    "                # Phòng ăn\n",
    "                has_dining_room = find_element_custom(0, 5)\n",
    "                # Nhà bếp\n",
    "                has_kitchen = find_element_custom(1, 5)\n",
    "                # Sân thượng\n",
    "                has_rooftop = find_element_custom(2, 5)\n",
    "                # Chỗ để xe hơi\n",
    "                has_parking = find_element_custom(3, 5)\n",
    "                # Chính chủ\n",
    "                is_owner = find_element_custom(4, 5)\n",
    "                    \n",
    "                return {\n",
    "                    \"title\": title,\n",
    "                    \"price\": price,\n",
    "                    \"size\": size,\n",
    "                    \"unit\": unit,\n",
    "                    \"streetAddress\": streetAddress,\n",
    "                    \"addressLocality\": addressLocality,\n",
    "                    \"addressRegion\": addressRegion,\n",
    "                    \"time_update\": time_update,\n",
    "                    \"post_id\": post_id,\n",
    "                    \"direction\": direction,\n",
    "                    \"listing_type\": listing_type,\n",
    "                    \"road_width\": road_width,\n",
    "                    \"property_type\": property_type,\n",
    "                    \"legal_documents\": legal_documents,\n",
    "                    \"width\": width,\n",
    "                    \"length\": length,\n",
    "                    \"num_floors\": num_floors,\n",
    "                    \"num_bedrooms\": num_bedrooms,\n",
    "                    \"has_dining_room\": has_dining_room,\n",
    "                    \"has_kitchen\": has_kitchen,\n",
    "                    \"has_rooftop\": has_rooftop,\n",
    "                    \"has_parking\": has_parking,\n",
    "                    \"is_owner\": is_owner\n",
    "                }\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                retry_count += 1\n",
    "                logging.warning(f\"loi khi thu thap bai viet (lan {retry_count}/{max_retries}): {url}\")\n",
    "                if retry_count == max_retries:\n",
    "                    logging.error(f\"loi khi thu thap bai viet sau {max_retries} lan thu: {url}\")\n",
    "                    return None\n",
    "                time.sleep(random.uniform(3, 6))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"loi khong xac dinh khi xu ly bai viet {url}: {str(e)}\")\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "        \n",
    "    def run(self, scraper_links=True, have_link=False, scraper_data=True, start_from_links=0, start_from_page=1, end_to_page=1):\n",
    "        logging.info(f\"bat dau qua trinh thu nhap du lieu\")\n",
    "        self.scraper_link_totot(scraper_links = scraper_links, \n",
    "                                have_link=have_link, \n",
    "                                scraper_data=scraper_data, \n",
    "                                start_from_links=start_from_links, \n",
    "                                start_from_page=start_from_page, \n",
    "                                end_to_page=end_to_page\n",
    "                                )\n",
    "\n",
    "        logging.info(f\"da hoan thanh qua trinh thu nhap du lieu\")\n",
    "        logging.info(f\"tong so bai viet da thu thap: {len(self.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebbff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THÔNG TIN TỪ ẢNH CỦA BẠN (Đã thay IP và Port cho an toàn)\n",
    "PROXY_HOST = \"p.webshare.io\"\n",
    "PROXY_PORT = \"80\" # Hoặc Port khác nếu Webshare cung cấp\n",
    "PROXY_USER = \"qcjnyqiq-1\"\n",
    "PROXY_PASS = \"5xcpzg87hr6o\"\n",
    "\n",
    "# 1. Tạo chuỗi URL xác thực cho Proxy\n",
    "PROXY_AUTH_URL = f\"{PROXY_USER}:{PROXY_PASS}@{PROXY_HOST}:{PROXY_PORT}\"\n",
    "print(PROXY_AUTH_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1debab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập chỉ số proxi ip để xoay tua, tránh bị ban quá sớm, có thể thay đổi hoặc loại bỏ qua code (code hiênj tai chưa thêm bật tắt cào bằng proxi)\n",
    "PROXY_LIST = [\n",
    "    {\"http\": \"http://qcjnyqiq-1:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-1:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-2:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-2:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-3:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-3:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-4:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-4:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-5:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-5:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-6:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-6:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-7:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-7:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-8:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-8:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-9:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-9:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://qcjnyqiq-10:5xcpzg87hr6o@p.webshare.io:80\", \"https\": \"http://qcjnyqiq-10:5xcpzg87hr6o@p.webshare.io:80\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4699005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập chỉ số proxi ip để xoay tua, tránh bị ban quá sớm, có thể thay đổi hoặc loại bỏ qua code (code hiênj tai chưa thêm bật tắt cào bằng proxi)\n",
    "PROXY_LIST = [\n",
    "    {\"http\": \"http://yidvnayf-1:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-1:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-2:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-2:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-3:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-3:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-4:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-4:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-5:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-5:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-6:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-6:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-7:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-7:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-8:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-8:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-9:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-9:33aufycpcqrw@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://yidvnayf-10:33aufycpcqrw@p.webshare.io:80\", \"https\": \"http://yidvnayf-10:33aufycpcqrw@p.webshare.io:80\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập chỉ số proxi ip để xoay tua, tránh bị ban quá sớm, có thể thay đổi hoặc loại bỏ qua code (code hiênj tai chưa thêm bật tắt cào bằng proxi)\n",
    "PROXY_LIST = [\n",
    "    {\"http\": \"http://lboqeuum-1:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-1:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-2:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-2:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-3:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-3:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-4:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-4:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-5:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-5:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-6:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-6:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-7:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-7:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-8:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-8:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-9:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-9:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "    {\"http\": \"http://lboqeuum-10:0dsh1zpb2c30@p.webshare.io:80\", \"https\": \"http://lboqeuum-10:0dsh1zpb2c30@p.webshare.io:80\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1ff72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 08:30:18,066 - INFO - bat dau qua trinh thu nhap du lieu\n",
      "2025-10-16 08:30:18,119 - INFO - se xu ly 702 link (bo qua 810 link dau)\n",
      "thu nhap du lieu nha van dat:   0%|          | 2/702 [00:16<1:34:54,  8.13s/it]2025-10-16 08:30:37,917 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//-ban-nha-3-tang-duong-pham-huu-kinh-ngay-du-an-cosmo-dt-194m2-gia-chi-18-ty-tl-17485463.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   0%|          | 3/702 [00:19<1:08:27,  5.88s/it]2025-10-16 08:30:38,944 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//-ban-nha-duong-tran-quang-khai-10m5-gan-cong-vien-dt-127m2-gia-10-8-ty-17365667.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   1%|          | 4/702 [00:20<46:05,  3.96s/it]  2025-10-16 08:30:42,527 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//-ban-cap-dat-duong-ly-trien-gan-ha-huy-tap-dt-196m2-gia-13-5-ty-tl-16915625.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   1%|          | 5/702 [00:24<44:25,  3.82s/it]2025-10-16 08:30:44,517 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//-ban-nha-duong-ha-huy-tap-gan-pham-nhu-tang-dong-tien-7tr-thang-dt-53m2-gia-7-1-ty-17217570.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   1%|▏         | 9/702 [00:44<59:23,  5.14s/it]2025-10-16 08:31:05,379 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-nha-2-tang-duong-tieu-la-hoa-cuong-bac-hai-chau-da-nang-17101621.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   1%|▏         | 10/702 [00:47<52:14,  4.53s/it]2025-10-16 08:31:08,706 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//-can-ban-lo-dat-dep-tai-phuong-an-hoa-tp-hue-17486303.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   2%|▏         | 11/702 [00:50<47:55,  4.16s/it]2025-10-16 08:31:09,804 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//nha-pho-lien-ke-vua-o-vua-kinh-doanh-bcons-uni-valley-4-tang-so-hong-rieng-lau-dai-17402915.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   2%|▏         | 12/702 [00:51<37:08,  3.23s/it]2025-10-16 08:31:10,912 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-dat-duong-2-lan-dien-hong-hoa-xuan-nhieu-vi-tri-tren-truc-duong-15646642.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   2%|▏         | 13/702 [00:52<29:42,  2.59s/it]2025-10-16 08:31:11,969 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-lo-biet-thu-duong-nguyen-hoi-phuong-nguyen-an-ninh-trung-tam-vung-tau-15858421.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   2%|▏         | 14/702 [00:53<24:22,  2.13s/it]2025-10-16 08:31:12,480 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-nha-2-phong-ngu-hem-6m-cach-le-van-luong-50m-17263278.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   2%|▏         | 15/702 [00:54<18:45,  1.64s/it]2025-10-16 08:31:16,511 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-nha-hem-xe-hoi-1368-le-van-luong-phuoc-kien-nha-be-17197978.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   2%|▏         | 16/702 [00:58<26:58,  2.36s/it]2025-10-16 08:31:17,632 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//biet-thu-so-12-duong-so-20-p-binh-an-quan-2-dien-tich-20x30m-4-tang-gia-150-ty-17483831.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   2%|▏         | 17/702 [00:59<22:40,  1.99s/it]2025-10-16 08:31:18,751 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-nha-3-mat-tien-ung-van-khiem-p-25-q-binh-thanh-dien-tich-46-x-45m-gia-600-ty-17483921.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   3%|▎         | 18/702 [01:00<19:40,  1.73s/it]2025-10-16 08:31:19,887 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-nha-sieu-vi-tri-2-mat-tien-nguyen-van-troi-truong-quoc-dung-ngang-4m-hdt-50tr-th-17467062.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   3%|▎         | 19/702 [01:01<17:38,  1.55s/it]2025-10-16 08:31:21,013 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//giam-4x20m-ban-nha-khu-k300-nguyen-minh-hoang-tret-lung-2-lau-st-chi-13-5ty-17485450.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   3%|▎         | 20/702 [01:02<16:09,  1.42s/it]2025-10-16 08:31:23,937 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//chdv-trung-tam-thanh-xuan-dt-56m-lo-goc-2-thoang-9p-cho-thue-full-do-pccc-gia-chi-200tr-m-17485437.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   3%|▎         | 21/702 [01:05<21:15,  1.87s/it]2025-10-16 08:31:25,043 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//-ban-dat-mat-tien-duong-7m5-vu-lap-100-m2-lien-chieu-da-nang-gia-4-7-ty-tl-17484502.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   3%|▎         | 22/702 [01:06<18:36,  1.64s/it]2025-10-16 08:31:26,162 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//-ktdc-trung-tam-binh-duong-thuoc-da-nang-gan-bien-17485429.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   3%|▎         | 23/702 [01:07<16:48,  1.49s/it]2025-10-16 08:31:26,957 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-nha-3-tang-tan-co-dien-cach-cho-an-cuu-500m-full-noi-that-17424171.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   3%|▎         | 24/702 [01:08<14:27,  1.28s/it]2025-10-16 08:31:28,071 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-dat-trong-mt-phan-khoang-duong-7m5-hoa-an-cam-le-112m2-gia-4-ty-85-17327775.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   4%|▎         | 25/702 [01:09<13:52,  1.23s/it]2025-10-16 08:31:29,144 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-nha-c4-mt-nguyen-do-cung-nha-cho-thue-lien-chieu-dt-83m2-gia-4-ty-65-tl-17417498.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   4%|▎         | 26/702 [01:10<13:19,  1.18s/it]2025-10-16 08:31:29,542 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-nha-c4-dt-lon-198m2-mt-trung-nghia-1-doi-dien-cong-vien-hoa-minh-lien-chieu-gia-6-t-15693388.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   4%|▍         | 27/702 [01:11<10:39,  1.06it/s]2025-10-16 08:31:30,594 - ERROR - loi khong xac dinh khi xu ly bai viet https://alonhadat.com.vn//ban-dat-kem-tro-c4-moi-mt-trieu-quoc-dat-gan-nguyen-phuoc-tan-q-cam-le-77-6m2-4-ty-35-17355830.html: 'NoneType' object has no attribute 'split'\n",
      "thu nhap du lieu nha van dat:   4%|▍         | 28/702 [01:14<29:52,  2.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m scraper = cho_van_tot(PROXY_LIST=PROXY_LIST)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mscraper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscraper_links\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhave_link\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[43mscraper_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstart_from_links\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m810\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstart_from_page\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43mend_to_page\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 285\u001b[39m, in \u001b[36mcho_van_tot.run\u001b[39m\u001b[34m(self, scraper_links, have_link, scraper_data, start_from_links, start_from_page, end_to_page)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, scraper_links=\u001b[38;5;28;01mTrue\u001b[39;00m, have_link=\u001b[38;5;28;01mFalse\u001b[39;00m, scraper_data=\u001b[38;5;28;01mTrue\u001b[39;00m, start_from_links=\u001b[32m0\u001b[39m, start_from_page=\u001b[32m1\u001b[39m, end_to_page=\u001b[32m1\u001b[39m):\n\u001b[32m    284\u001b[39m     logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbat dau qua trinh thu nhap du lieu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscraper_link_totot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscraper_links\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mscraper_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mhave_link\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhave_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mscraper_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscraper_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mstart_from_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_from_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mstart_from_page\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_from_page\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mend_to_page\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_to_page\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mda hoan thanh qua trinh thu nhap du lieu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    294\u001b[39m     logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtong so bai viet da thu thap: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mcho_van_tot.scraper_link_totot\u001b[39m\u001b[34m(self, scraper_links, have_link, scraper_data, start_from_links, start_from_page, end_to_page)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    112\u001b[39m     actual_index = start_from_links + num\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     article_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscraper_data_cho_van_tot\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle_info\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m article_data:\n\u001b[32m    116\u001b[39m         \u001b[38;5;28mself\u001b[39m.data.append(article_data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 153\u001b[39m, in \u001b[36mcho_van_tot.scraper_data_cho_van_tot\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# Xoay vòng proxy\u001b[39;00m\n\u001b[32m    152\u001b[39m current_proxies = random.choice(\u001b[38;5;28mself\u001b[39m.PROXY_LIST)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_proxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\n\u001b[32m    158\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m429\u001b[39m:\n\u001b[32m    161\u001b[39m     retry_after = \u001b[32m60\u001b[39m  \u001b[38;5;66;03m# Mặc định 60s\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\requests\\sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\urllib3\\connectionpool.py:773\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m http_tunnel_required \u001b[38;5;129;01mand\u001b[39;00m conn.is_closed:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m, SocketTimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    775\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(\n\u001b[32m    776\u001b[39m             err=e, url=\u001b[38;5;28mself\u001b[39m.proxy.url, timeout_value=conn.timeout\n\u001b[32m    777\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[39m, in \u001b[36mHTTPSConnectionPool._prepare_proxy\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1034\u001b[39m     tunnel_scheme = \u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1036\u001b[39m conn.set_tunnel(\n\u001b[32m   1037\u001b[39m     scheme=tunnel_scheme,\n\u001b[32m   1038\u001b[39m     host=\u001b[38;5;28mself\u001b[39m._tunnel_host,\n\u001b[32m   1039\u001b[39m     port=\u001b[38;5;28mself\u001b[39m.port,\n\u001b[32m   1040\u001b[39m     headers=\u001b[38;5;28mself\u001b[39m.proxy_headers,\n\u001b[32m   1041\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1042\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m     \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[32m    788\u001b[39m     server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# If an error occurs during connection/handshake we may need to release\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# our lock so another connection can probe the origin.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\urllib3\\connection.py:969\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[32m    967\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    983\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\urllib3\\util\\ssl_.py:480\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    476\u001b[39m         context.load_cert_chain(certfile, keyfile, key_password)\n\u001b[32m    478\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\site-packages\\urllib3\\util\\ssl_.py:524\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    521\u001b[39m     SSLTransport._validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\ssl.py:1076\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1073\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m:\n\u001b[32m   1074\u001b[39m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[32m   1075\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1078\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\anaconda3\\envs\\aio\\Lib\\ssl.py:1372\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28mself\u001b[39m.settimeout(timeout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "scraper = cho_van_tot(PROXY_LIST=PROXY_LIST)\n",
    "scraper.run(scraper_links=False, \n",
    "            have_link=True,\n",
    "            scraper_data=True, \n",
    "            start_from_links=810, \n",
    "            start_from_page=0, \n",
    "            end_to_page=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aca4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH = \"C:/Users/VICTUS/Desktop/create/cho_van_tot/all_articles.csv\"\n",
    "test = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1693c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7490339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r'C:\\Users\\VICTUS\\Desktop\\create\\cho_van_tot\\data_output\\all_articles.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f845a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"khaibaybe.csv\")\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
